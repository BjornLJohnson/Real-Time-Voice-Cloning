{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bjorn/dev/ECE_228/228/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/home/bjorn/dev/ECE_228/228/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "from encoder.params_model import model_embedding_size as speaker_embedding_size\n",
    "from encoder import inference as encoder\n",
    "from vocoder import inference as vocoder\n",
    "# from contentEncoder import model as ContentEncoder\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a test of your configuration...\n",
      "\n",
      "Found 1 GPUs available. Using GPU 0 (GeForce GTX 960M) of compute capability 5.0 with 4.2Gb total memory.\n",
      "\n",
      "Preparing the encoder, the synthesizer and the vocoder...\n",
      "SpeechRecognitionModel(\n",
      "  (cnn): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (rescnn_layers): Sequential(\n",
      "    (0): ResidualCNN(\n",
      "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      (layer_norm1): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (layer_norm2): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualCNN(\n",
      "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      (layer_norm1): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (layer_norm2): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualCNN(\n",
      "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      (layer_norm1): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (layer_norm2): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  (birnn_layers): Sequential(\n",
      "    (0): BidirectionalGRU(\n",
      "      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (3): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (4): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): GELU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=29, bias=True)\n",
      "  )\n",
      ")\n",
      "Num Model Parameters 23705373\n",
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "Parameter containing:\n",
      "tensor([[[[-3.3453e-03, -1.3368e-01, -1.5159e-03],\n",
      "          [-2.4849e-03,  3.2238e-04, -4.8849e-04],\n",
      "          [ 3.0585e-03, -4.4831e-02, -1.0533e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5842e-02,  4.2214e-02, -1.1978e-01],\n",
      "          [ 4.3343e-03,  5.1432e-03, -3.7207e-02],\n",
      "          [-1.4790e-03,  3.8959e-02, -5.8848e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5638e-02, -1.0115e-01,  9.7995e-02],\n",
      "          [-2.1390e-02,  3.9470e-02,  1.2833e-02],\n",
      "          [-2.1501e-03,  5.7551e-02,  1.4183e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.4866e-02,  4.4531e-01, -3.9061e-02],\n",
      "          [ 7.2485e-02,  3.9121e-01,  6.1064e-05],\n",
      "          [ 1.5178e-01,  4.5227e-01,  5.7022e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0485e-01, -2.8200e-01, -9.5221e-03],\n",
      "          [-4.2433e-02,  4.4678e-02, -1.6305e-02],\n",
      "          [-1.9730e-01,  8.4880e-02,  1.4816e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3544e-02, -9.4897e-03, -2.8973e-02],\n",
      "          [ 2.6496e-02, -7.6514e-02, -1.5234e-01],\n",
      "          [ 7.0304e-03, -4.0497e-03, -1.2580e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.7571e-02,  3.1573e-02,  8.9266e-04],\n",
      "          [-3.1069e-02,  3.1390e-02, -1.2842e-03],\n",
      "          [-2.4829e-02,  1.0113e-02,  1.7792e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.2711e-02, -4.4193e-01, -1.8268e-03],\n",
      "          [-3.7373e-03,  2.6384e-02,  6.3264e-04],\n",
      "          [-3.1393e-02, -4.0771e-01, -2.2641e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8290e-01, -1.3454e-01, -1.2808e-01],\n",
      "          [ 1.8838e-01, -5.2790e-02, -1.2838e-01],\n",
      "          [ 1.2525e-01, -7.2222e-02, -4.4679e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9528e-02, -6.7217e-03,  6.8611e-03],\n",
      "          [ 6.0508e-03, -8.0798e-02,  6.7492e-02],\n",
      "          [ 4.3832e-04, -1.3932e-01,  1.2251e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1108e-01, -1.8980e-02, -7.6332e-04],\n",
      "          [-4.8336e-04, -5.8691e-04, -9.8575e-04],\n",
      "          [-2.9579e-01, -1.7498e-02, -9.6490e-04]]],\n",
      "\n",
      "\n",
      "        [[[-8.2929e-03,  1.6185e-03, -4.0247e-01],\n",
      "          [-5.9194e-03, -5.3487e-03,  5.4322e-02],\n",
      "          [-8.5714e-04, -2.0019e-02, -4.3474e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5379e-02, -2.4621e-03, -3.5302e-01],\n",
      "          [ 7.6527e-04,  5.8663e-03, -4.4697e-03],\n",
      "          [ 4.0552e-03, -2.4651e-02, -8.3561e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0805e-02, -1.0528e-01,  5.5726e-02],\n",
      "          [ 1.4329e-02, -6.6275e-02,  4.8442e-02],\n",
      "          [-2.5363e-03, -1.0704e-01, -1.7995e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.6542e-01, -2.2328e-02,  3.9284e-02],\n",
      "          [ 6.1982e-02, -1.5150e-02, -1.5547e-03],\n",
      "          [-2.2796e-01,  3.3935e-03,  6.9435e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6425e-02, -4.5132e-02, -1.4757e-03],\n",
      "          [ 2.3806e-02, -2.8095e-02,  3.1350e-04],\n",
      "          [-3.4385e-03,  8.6550e-03, -5.1249e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.6833e-02, -4.9186e-01, -1.7897e-03],\n",
      "          [-9.4837e-03,  4.4939e-02, -2.7384e-03],\n",
      "          [ 6.7101e-03, -5.9145e-01, -7.2864e-04]]],\n",
      "\n",
      "\n",
      "        [[[-4.9446e-02,  5.1532e-02, -9.9569e-03],\n",
      "          [-1.9105e-01,  1.0639e-01,  3.1251e-02],\n",
      "          [-2.2645e-01, -1.1910e-01, -1.4304e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2313e-02, -1.9893e-01,  1.3264e-02],\n",
      "          [-1.8414e-03, -8.0594e-03,  2.9484e-03],\n",
      "          [ 4.2186e-03, -4.8586e-02,  7.2354e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.9430e-01,  6.2563e-02, -2.6786e-03],\n",
      "          [-4.8207e-03, -6.5494e-04,  1.9822e-03],\n",
      "          [-9.9462e-02,  1.9063e-02, -2.9148e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9169e-03,  3.7896e-02, -5.5090e-02],\n",
      "          [-4.7432e-03,  9.2989e-04,  2.0705e-03],\n",
      "          [-2.1424e-01,  1.7500e-01,  4.5727e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9748e-02,  2.2158e-01,  2.6246e-02],\n",
      "          [ 1.2281e-01, -1.2264e-01,  4.1457e-02],\n",
      "          [-3.9522e-02,  5.1686e-02, -6.4996e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1497e-01, -4.5409e-01, -4.1886e-03],\n",
      "          [ 9.6636e-02, -9.6968e-02,  1.7725e-03],\n",
      "          [ 8.3954e-02, -3.3682e-01,  5.9454e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.3136e-04,  3.3802e-02, -3.0793e-02],\n",
      "          [-5.3305e-03,  6.6601e-02, -7.7329e-02],\n",
      "          [ 6.9917e-03,  9.5024e-02, -1.5662e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1608e-02,  2.5249e-03,  4.3547e-04],\n",
      "          [-5.4545e-03,  5.1927e-03, -5.4220e-04],\n",
      "          [-1.1698e-01,  3.7644e-03, -1.6355e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.2474e-03, -3.3240e-03, -9.3359e-03],\n",
      "          [-1.0220e-02, -2.1864e-01, -6.4212e-02],\n",
      "          [ 6.8354e-04,  1.3052e-02,  4.1754e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.1608e-02,  5.3553e-02, -5.4567e-02],\n",
      "          [-5.8098e-02,  1.1805e-01, -8.2837e-02],\n",
      "          [ 1.3326e-03,  2.7849e-02, -3.2676e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.8079e-03, -3.6396e-02,  8.7097e-04],\n",
      "          [-3.1876e-02, -1.6912e-01, -9.7794e-04],\n",
      "          [ 4.7981e-03, -1.3952e-01, -3.9530e-03]]],\n",
      "\n",
      "\n",
      "        [[[-7.7913e-02,  4.6090e-02, -1.1225e-01],\n",
      "          [ 7.2473e-02,  1.8015e-01, -4.7990e-02],\n",
      "          [-3.8008e-02, -3.2684e-02, -2.3793e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6530e-01,  4.4041e-02, -2.9902e-01],\n",
      "          [-1.9003e-02,  1.7541e-02,  7.3052e-03],\n",
      "          [-2.0172e-01, -2.3227e-01,  9.8024e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.8535e-01, -7.1580e-01,  2.0786e-03],\n",
      "          [ 9.1778e-03, -3.7839e-02, -4.7973e-03],\n",
      "          [-2.6608e-01, -9.7523e-01,  4.7798e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.5504e-03,  1.3646e-01,  1.8244e-01],\n",
      "          [-2.4666e-03, -1.2654e-02, -2.1777e-02],\n",
      "          [-2.9020e-03, -3.9002e-01, -4.8680e-01]]]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Sequential(\n",
      "  (0): ResidualCNN(\n",
      "    (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    (layer_norm1): CNNLayerNorm(\n",
      "      (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (layer_norm2): CNNLayerNorm(\n",
      "      (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (1): ResidualCNN(\n",
      "    (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    (layer_norm1): CNNLayerNorm(\n",
      "      (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (layer_norm2): CNNLayerNorm(\n",
      "      (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (2): ResidualCNN(\n",
      "    (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    (layer_norm1): CNNLayerNorm(\n",
      "      (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (layer_norm2): CNNLayerNorm(\n",
      "      (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0416, -0.0104,  0.0038],\n",
      "          [-0.0736, -0.1440,  0.0009],\n",
      "          [-0.0151, -0.1491,  0.0111]],\n",
      "\n",
      "         [[-0.0704,  0.0692,  0.0225],\n",
      "          [-0.2357,  0.0274,  0.0417],\n",
      "          [-0.0726,  0.0441, -0.0662]],\n",
      "\n",
      "         [[-0.0317, -0.0132, -0.0727],\n",
      "          [ 0.0034,  0.0141, -0.0294],\n",
      "          [-0.0726, -0.0344, -0.0326]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0448, -0.1275, -0.0617],\n",
      "          [-0.0453, -0.2530, -0.0011],\n",
      "          [-0.1513,  0.1028, -0.0325]],\n",
      "\n",
      "         [[-0.0053,  0.0084, -0.0409],\n",
      "          [-0.0409, -0.0394,  0.0594],\n",
      "          [ 0.0423, -0.0275, -0.0088]],\n",
      "\n",
      "         [[-0.0338, -0.2672, -0.0537],\n",
      "          [-0.0846, -0.2590,  0.0178],\n",
      "          [ 0.0367, -0.0163, -0.0659]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0505,  0.0401, -0.0394],\n",
      "          [ 0.0694,  0.0720, -0.0929],\n",
      "          [-0.0701,  0.1077,  0.0071]],\n",
      "\n",
      "         [[-0.0757, -0.0187, -0.0335],\n",
      "          [-0.1503,  0.1010, -0.0647],\n",
      "          [-0.1126, -0.0461, -0.0334]],\n",
      "\n",
      "         [[-0.1104, -0.0663, -0.0528],\n",
      "          [-0.0969, -0.1348,  0.0144],\n",
      "          [ 0.0091, -0.0013,  0.0320]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0140, -0.0612,  0.0970],\n",
      "          [-0.1007, -0.0033,  0.0765],\n",
      "          [-0.1581,  0.0309, -0.0023]],\n",
      "\n",
      "         [[-0.0587,  0.0492, -0.0376],\n",
      "          [ 0.0180,  0.0497, -0.0517],\n",
      "          [-0.1105,  0.0230, -0.1728]],\n",
      "\n",
      "         [[-0.0994,  0.0545, -0.0550],\n",
      "          [-0.1336, -0.0307, -0.2775],\n",
      "          [-0.1671, -0.0388, -0.2578]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0104, -0.0235,  0.0221],\n",
      "          [-0.0062,  0.0602,  0.0896],\n",
      "          [ 0.0073, -0.0509, -0.0615]],\n",
      "\n",
      "         [[-0.0161, -0.0614, -0.0022],\n",
      "          [-0.0536, -0.0484, -0.0995],\n",
      "          [ 0.0589,  0.0022,  0.0050]],\n",
      "\n",
      "         [[ 0.0161, -0.0876, -0.0531],\n",
      "          [ 0.2111,  0.1400,  0.0626],\n",
      "          [-0.0169, -0.0026, -0.0046]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0062, -0.0156,  0.0730],\n",
      "          [-0.0753,  0.0172, -0.0165],\n",
      "          [ 0.0070, -0.0067,  0.0113]],\n",
      "\n",
      "         [[ 0.0170, -0.1013,  0.0066],\n",
      "          [-0.2108, -0.1704, -0.0811],\n",
      "          [-0.0756, -0.1024, -0.1419]],\n",
      "\n",
      "         [[-0.0406, -0.0112, -0.0474],\n",
      "          [-0.1726, -0.2063, -0.2209],\n",
      "          [ 0.1653,  0.2197,  0.1042]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0699,  0.0444,  0.0207],\n",
      "          [ 0.0858, -0.0254,  0.0065],\n",
      "          [ 0.0050,  0.0494,  0.0728]],\n",
      "\n",
      "         [[ 0.0672, -0.0927, -0.0931],\n",
      "          [ 0.0144, -0.1005,  0.0049],\n",
      "          [-0.0095,  0.0054,  0.0321]],\n",
      "\n",
      "         [[-0.0347,  0.0377,  0.0212],\n",
      "          [ 0.0173, -0.0257,  0.0242],\n",
      "          [-0.0786, -0.0603, -0.0168]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0249,  0.1008,  0.0209],\n",
      "          [-0.0079, -0.2064, -0.0516],\n",
      "          [-0.0919, -0.1647,  0.0064]],\n",
      "\n",
      "         [[-0.0823, -0.0994, -0.0687],\n",
      "          [-0.0775, -0.0673, -0.0010],\n",
      "          [ 0.0133, -0.0186,  0.0688]],\n",
      "\n",
      "         [[-0.0125, -0.3138, -0.0465],\n",
      "          [ 0.0848,  0.0918,  0.1340],\n",
      "          [-0.0049,  0.1240,  0.0772]]],\n",
      "\n",
      "\n",
      "        [[[-0.0541, -0.0259, -0.0584],\n",
      "          [-0.0417,  0.0100, -0.0020],\n",
      "          [ 0.0132,  0.1349,  0.0331]],\n",
      "\n",
      "         [[ 0.0455, -0.0555, -0.0147],\n",
      "          [ 0.0574,  0.0011, -0.0066],\n",
      "          [ 0.0155, -0.0397, -0.0516]],\n",
      "\n",
      "         [[-0.0238,  0.0502,  0.0266],\n",
      "          [-0.0139, -0.1097, -0.0516],\n",
      "          [-0.0479, -0.0825, -0.0554]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0460, -0.0658,  0.0130],\n",
      "          [ 0.0438, -0.0919,  0.0418],\n",
      "          [ 0.0081, -0.0092,  0.0170]],\n",
      "\n",
      "         [[-0.0006, -0.0466, -0.0460],\n",
      "          [ 0.0707,  0.0744,  0.0479],\n",
      "          [ 0.0613, -0.0947, -0.0640]],\n",
      "\n",
      "         [[-0.0056, -0.1307, -0.0121],\n",
      "          [-0.0040, -0.0874,  0.0713],\n",
      "          [-0.1056, -0.1652,  0.0694]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0266,  0.0043,  0.0751],\n",
      "          [ 0.1146, -0.0971,  0.0264],\n",
      "          [ 0.0821, -0.1061, -0.0461]],\n",
      "\n",
      "         [[-0.1044,  0.0902, -0.0230],\n",
      "          [ 0.0361,  0.0024, -0.0858],\n",
      "          [-0.0301,  0.0062,  0.0119]],\n",
      "\n",
      "         [[-0.0167,  0.0928,  0.0029],\n",
      "          [-0.0032,  0.1253,  0.0031],\n",
      "          [-0.0015, -0.0015, -0.0112]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2109, -0.0078, -0.0160],\n",
      "          [-0.0309,  0.0567,  0.0139],\n",
      "          [ 0.0310,  0.0443, -0.0084]],\n",
      "\n",
      "         [[-0.0818,  0.0554, -0.0047],\n",
      "          [-0.0707, -0.1414, -0.0798],\n",
      "          [-0.0768, -0.1126, -0.1538]],\n",
      "\n",
      "         [[-0.0301, -0.0428, -0.0951],\n",
      "          [ 0.0476, -0.0118, -0.0678],\n",
      "          [-0.0767,  0.0481, -0.0731]]]], device='cuda:0', requires_grad=True)\n",
      "Linear(in_features=2048, out_features=512, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1198,  0.0192,  0.1155,  ...,  0.0522, -0.0241, -0.1311],\n",
      "        [-0.1693, -0.1507, -0.1734,  ..., -0.0452, -0.0189,  0.0388],\n",
      "        [ 0.1218,  0.1007, -0.0432,  ..., -0.0893, -0.0352,  0.0254],\n",
      "        ...,\n",
      "        [-0.0233,  0.0337, -0.0142,  ...,  0.0217,  0.0084,  0.0570],\n",
      "        [-0.0303, -0.1277, -0.1721,  ..., -0.0658, -0.0921, -0.0728],\n",
      "        [ 0.0413,  0.0194,  0.0540,  ...,  0.1197,  0.0052, -0.0684]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Sequential(\n",
      "  (0): BidirectionalGRU(\n",
      "    (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): BidirectionalGRU(\n",
      "    (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (2): BidirectionalGRU(\n",
      "    (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (3): BidirectionalGRU(\n",
      "    (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (4): BidirectionalGRU(\n",
      "    (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[-0.0550,  0.0118,  0.0142,  ...,  0.0398,  0.0252, -0.0072],\n",
      "        [-0.0572,  0.0963,  0.0284,  ..., -0.0032, -0.0341, -0.0524],\n",
      "        [ 0.0399,  0.0215, -0.1443,  ...,  0.0581,  0.0349,  0.0881],\n",
      "        ...,\n",
      "        [-0.0345,  0.0197, -0.0385,  ..., -0.0341, -0.0181,  0.0654],\n",
      "        [-0.0288, -0.0593, -0.0107,  ...,  0.0492, -0.0032,  0.0353],\n",
      "        [-0.0115,  0.0879,  0.0208,  ..., -0.0342,  0.0103,  0.0402]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Sequential(\n",
      "  (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (1): GELU()\n",
      "  (2): Dropout(p=0.1, inplace=False)\n",
      "  (3): Linear(in_features=512, out_features=29, bias=True)\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([[-4.9286e-02, -5.6960e-03,  6.9197e-03,  ..., -3.8036e-02,\n",
      "         -6.9879e-02, -8.4834e-02],\n",
      "        [ 1.1646e-01,  4.2349e-02, -2.8677e-02,  ..., -3.9495e-02,\n",
      "         -2.1238e-02, -5.1299e-02],\n",
      "        [ 7.4234e-05, -6.0284e-02, -6.2085e-02,  ..., -2.3065e-02,\n",
      "         -1.6189e-02, -1.1079e-01],\n",
      "        ...,\n",
      "        [ 2.5710e-02,  3.3987e-02, -8.8996e-03,  ...,  7.6189e-03,\n",
      "         -3.4876e-02, -7.3972e-02],\n",
      "        [-1.1355e-02, -5.6216e-02, -1.4732e-02,  ...,  1.4530e-02,\n",
      "         -2.6669e-02, -5.5545e-02],\n",
      "        [ 4.1730e-03,  4.1159e-02,  6.9435e-03,  ..., -2.8966e-02,\n",
      "          3.3453e-02, -2.4633e-02]], device='cuda:0', requires_grad=True)\n",
      "Loaded encoder \"pretrained.pt\" trained to step 1564501\n"
     ]
    }
   ],
   "source": [
    "# Set paths and load the models\n",
    "args={\"enc_model_fpath\": Path(\"encoder/saved_models/pretrained.pt\"),\n",
    "      \"syn_model_dir\": Path(\"synthesizer/saved_models/logs-pretrained/\"),\n",
    "      \"voc_model_fpath\": Path(\"vocoder/saved_models/pretrained/pretrained.pt\"),\n",
    "      \"styleAudio\": Path(\"data/styleAudio/rand1.flac\"),\n",
    "      \"contentAudio\":  \"./data/contentAudio/121-121726-0010.flac\",\n",
    "      \"content_model_fpath\": \"contentEncoder/saved_models/deepspeech4.pt\",}\n",
    "\n",
    "\n",
    "## Print some environment information (for debugging purposes)\n",
    "print(\"Running a test of your configuration...\\n\")\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"Your PyTorch installation is not configured to use CUDA. If you have a GPU ready \"\n",
    "          \"for deep learning, ensure that the drivers are properly installed, and that your \"\n",
    "          \"CUDA version matches your PyTorch installation. CPU-only inference is currently \"\n",
    "          \"not supported.\",)# file=sys.stderr)\n",
    "    quit(-1)\n",
    "device_id = torch.cuda.current_device()\n",
    "gpu_properties = torch.cuda.get_device_properties(device_id)\n",
    "print(\"Found %d GPUs available. Using GPU %d (%s) of compute capability %d.%d with \"\n",
    "      \"%.1fGb total memory.\\n\" % \n",
    "      (torch.cuda.device_count(),\n",
    "       device_id,\n",
    "       gpu_properties.name,\n",
    "       gpu_properties.major,\n",
    "       gpu_properties.minor,\n",
    "       gpu_properties.total_memory / 1e9))\n",
    "\n",
    "\n",
    "## Load the models one by one.\n",
    "print(\"Preparing the encoder, the synthesizer and the vocoder...\")\n",
    "ContentEncoder.load_model(args['content_model_fpath'])\n",
    "encoder.load_model(args[\"enc_model_fpath\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file succesfully\n",
      "Created the embedding\n",
      "['howsecleaning ay de mestick u hebiledthat makes it easy for the government to inlist all the soldiers it neds']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/bjorn/.cache/torch/hub/nvidia_DeepLearningExamples_torchhub\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vocoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7c5c8a0a008b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# # Synthesizing the waveform is fairly straightforward. Remember that the longer the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# # spectrogram, the more time-efficient the vocoder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mgenerated_wav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_waveform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocoder' is not defined"
     ]
    }
   ],
   "source": [
    "## Computing the embedding\n",
    "# First, we load the wav using the function that the speaker encoder provides. This is \n",
    "# important: there is preprocessing that must be applied.\n",
    "\n",
    "# The following two methods are equivalent:\n",
    "# - Directly load from the filepath:\n",
    "preprocessed_wav = encoder.preprocess_wav(args['styleAudio'])\n",
    "# - If the wav is already loaded:\n",
    "original_wav, sampling_rate = librosa.load(args['styleAudio'])\n",
    "preprocessed_wav = encoder.preprocess_wav(original_wav, sampling_rate)\n",
    "print(\"Loaded file succesfully\")\n",
    "\n",
    "# Then we derive the embedding. There are many functions and parameters that the \n",
    "# speaker encoder interfaces. These are mostly for in-depth research. You will typically\n",
    "# only use this function (with its default parameters):\n",
    "embed = encoder.embed_utterance(preprocessed_wav)\n",
    "print(\"Created the embedding\")\n",
    "\n",
    "# The synthesizer works in batch, so you need to put your data in a list or numpy array\n",
    "text = ContentEncoder.generate_text(args['contentAudio'])\n",
    "print(text)\n",
    "# texts = [text]\n",
    "embeds = [embed]\n",
    "\n",
    "\n",
    "tacotron2 = tacotron2.to('cuda')\n",
    "tacotron2.eval()\n",
    "\n",
    "waveglow = torch.hub.load('nvidia/DeepLearningExamples:torchhub', 'nvidia_waveglow')\n",
    "waveglow = waveglow.remove_weightnorm(waveglow)\n",
    "waveglow = waveglow.to('cuda')\n",
    "waveglow.eval()\n",
    "\n",
    "# text = \"hello world, I missed you\"\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "sequence = np.array(tacotron2.text_to_sequence(text, ['english_cleaners']))[None, :]\n",
    "sequence = torch.from_numpy(sequence).to(device='cuda', dtype=torch.int64)\n",
    "\n",
    "# run the models\n",
    "with torch.no_grad():\n",
    "    _, mel, _, _ = tacotron2.infer(sequence)\n",
    "    audio = waveglow.infer(mel)\n",
    "audio_numpy = audio[0].data.cpu().numpy()\n",
    "rate = 22050\n",
    "\n",
    "\n",
    "# write(\"audio.wav\", rate, audio_numpy)\n",
    "\n",
    "\n",
    "# from IPython.display import Audio\n",
    "# Audio(audio_numpy, rate=rate)\n",
    "\n",
    "\n",
    "# # If you know what the attention layer alignments are, you can retrieve them here by\n",
    "# # passing return_alignments=True\n",
    "# specs = synthesizer.synthesize_spectrograms(texts, embeds)\n",
    "# spec = specs[0]\n",
    "# print(\"Created the mel spectrogram\")\n",
    "\n",
    "\n",
    "# ## Generating the waveform\n",
    "# print(\"Synthesizing the waveform:\")\n",
    "# # Synthesizing the waveform is fairly straightforward. Remember that the longer the\n",
    "# # spectrogram, the more time-efficient the vocoder.\n",
    "generated_wav = vocoder.infer_waveform(mel)\n",
    "\n",
    "\n",
    "# ## Post-generation\n",
    "# # There's a bug with sounddevice that makes the audio cut one second earlier, so we\n",
    "# # pad it.\n",
    "# generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")\n",
    "\n",
    "# # Play the audio (non-blocking)\n",
    "# sd.stop()\n",
    "# sd.play(generated_wav, synthesizer.sample_rate)\n",
    "\n",
    "# # Save it on the disk\n",
    "# fpath = \"demo_output.wav\"\n",
    "# print(generated_wav.dtype)\n",
    "# librosa.output.write_wav(fpath, generated_wav.astype(np.float32), \n",
    "#                          synthesizer.sample_rate)\n",
    "\n",
    "# print(\"\\nSaved output as %s\\n\\n\" % fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "228",
   "language": "python",
   "name": "228"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
